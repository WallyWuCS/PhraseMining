{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhb7pgv6ZoQ6xrQaEm7PAB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WallyWuCS/PhraseMining/blob/main/CS512_MP1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVfROmdnbX04",
        "outputId": "839f3add-6655-4b67-d6f8-43e01ada90fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AutoPhrase'...\n",
            "remote: Enumerating objects: 967, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 967 (delta 66), reused 124 (delta 60), pack-reused 830\u001b[K\n",
            "Receiving objects: 100% (967/967), 199.80 MiB | 10.38 MiB/s, done.\n",
            "Resolving deltas: 100% (438/438), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/shangjingbo1226/AutoPhrase.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd AutoPhrase/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a4JaODkcHUr",
        "outputId": "d9ddfc10-5c67-4181-b9ae-0c88a2588a9a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AutoPhrase\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ./auto_phrase.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFxZQL6xcOPp",
        "outputId": "97e108a3-989a-480d-cf14-c6308d4c2810"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m===Compilation===\u001b[m\n",
            "mkdir -p bin\n",
            "g++ -std=c++11 -Wall -O3 -msse2  -fopenmp  -I.. -pthread -lm -Wno-unused-result -Wno-sign-compare -Wno-unused-variable -Wno-parentheses -Wno-format -o bin/segphrase_train src/main.cpp\n",
            "g++ -std=c++11 -Wall -O3 -msse2  -fopenmp  -I.. -pthread -lm -Wno-unused-result -Wno-sign-compare -Wno-unused-variable -Wno-parentheses -Wno-format -o bin/segphrase_segment src/segment.cpp\n",
            "\u001b[32m===Downloading Toy Dataset===\u001b[m\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  198M  100  198M    0     0  52.6M      0  0:00:03  0:00:03 --:--:-- 52.6M\n",
            "\u001b[32m===Tokenization===\u001b[m\n",
            "\n",
            "real\t4m48.686s\n",
            "user\t7m48.538s\n",
            "sys\t0m16.757s\n",
            "Detected Language: EN\u001b[0K\n",
            "Current step: Tokenizing wikipedia phrases...\u001b[0K\n",
            "No provided expert labels.\u001b[0K\n",
            "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3253k  100 3253k    0     0  1818k      0  0:00:01  0:00:01 --:--:-- 1818k\n",
            "english parameter file (Linux, UTF8) installed.\n",
            "\n",
            "\u001b[32m===AutoPhrasing===\u001b[m\n",
            "=== Current Settings ===\n",
            "Iterations = 2\n",
            "Minimum Support Threshold = 10\n",
            "Maximum Length Threshold = 6\n",
            "POS-Tagging Mode Enabled\n",
            "Number of threads = 10\n",
            "Labeling Method = DPDN\n",
            "\tAuto labels from knowledge bases\n",
            "\tMax Positive Samples = -1\n",
            "=======\n",
            "Loading data...\n",
            "# of total tokens = 111149629\n",
            "max word token id = 553924\n",
            "# of documents = 5547032\n",
            "# of distinct POS tags = 57\n",
            "Mining frequent phrases...\n",
            "selected MAGIC = 553933\n",
            "# of frequent phrases = 1801956\n",
            "Extracting features...\n",
            "Constructing label pools...\n",
            "\tThe size of the positive pool = 32635\n",
            "\tThe size of the negative pool = 1762859\n",
            "# truth patterns = 201855\n",
            "Estimating Phrase Quality...\n",
            "Segmenting...\n",
            "Rectifying features...\n",
            "Estimating Phrase Quality...\n",
            "Segmenting...\n",
            "Dumping results...\n",
            "Done.\n",
            "\n",
            "real\t39m44.606s\n",
            "user\t61m37.162s\n",
            "sys\t3m1.042s\n",
            "\u001b[32m===Saving Model and Results===\u001b[m\n",
            "\u001b[32m===Generating Output===\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ./auto_phrase.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o8Vizx3Z7TC",
        "outputId": "6ee837ba-6932-40cc-b0be-e1c0d84d4e82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m===Compilation===\u001b[m\n",
            "\u001b[32m===Tokenization===\u001b[m\n",
            "\n",
            "real\t0m18.959s\n",
            "user\t0m31.189s\n",
            "sys\t0m2.351s\n",
            "Detected Language: EN\u001b[0K\n",
            "Current step: Tokenizing wikipedia phrases...\u001b[0K\n",
            "No provided expert labels.\u001b[0K\n",
            "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
            "Current step: Merging...\u001b[0K\n",
            "\u001b[32m===AutoPhrasing===\u001b[m\n",
            "=== Current Settings ===\n",
            "Iterations = 2\n",
            "Minimum Support Threshold = 10\n",
            "Maximum Length Threshold = 6\n",
            "POS-Tagging Mode Enabled\n",
            "Number of threads = 10\n",
            "Labeling Method = DPDN\n",
            "\tAuto labels from knowledge bases\n",
            "\tMax Positive Samples = -1\n",
            "=======\n",
            "Loading data...\n",
            "# of total tokens = 5631756\n",
            "max word token id = 71763\n",
            "# of documents = 120000\n",
            "# of distinct POS tags = 57\n",
            "Mining frequent phrases...\n",
            "selected MAGIC = 71777\n",
            "# of frequent phrases = 139137\n",
            "Extracting features...\n",
            "Constructing label pools...\n",
            "\tThe size of the positive pool = 15019\n",
            "\tThe size of the negative pool = 122975\n",
            "# truth patterns = 158486\n",
            "Estimating Phrase Quality...\n",
            "Segmenting...\n",
            "Rectifying features...\n",
            "Estimating Phrase Quality...\n",
            "Segmenting...\n",
            "Dumping results...\n",
            "Done.\n",
            "\n",
            "real\t1m37.592s\n",
            "user\t2m18.018s\n",
            "sys\t0m13.650s\n",
            "\u001b[32m===Saving Model and Results===\u001b[m\n",
            "\u001b[32m===Generating Output===\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +w auto_phrase.sh"
      ],
      "metadata": {
        "id": "_8v8cDqOOwoS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd AutoPhrase/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AAZLrrtNuXh",
        "outputId": "fe00a92d-804d-4757-8de7-e77f75776a56"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AutoPhrase\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod +w phrasal_segmentation.sh"
      ],
      "metadata": {
        "id": "2WRYQk9MNn_f"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./phrasal_segmentation.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ym0w4VnzZgPo",
        "outputId": "95d75aa1-0377-4a3e-eabf-581d206f87aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m===Compilation===\u001b[m\n",
            "\u001b[32m===Tokenization===\u001b[m\n",
            "java.io.FileNotFoundException: models/NEW/token_mapping.txt (No such file or directory)\n",
            "\tat java.base/java.io.FileInputStream.open0(Native Method)\n",
            "\tat java.base/java.io.FileInputStream.open(FileInputStream.java:219)\n",
            "\tat java.base/java.io.FileInputStream.<init>(FileInputStream.java:157)\n",
            "\tat java.base/java.io.FileInputStream.<init>(FileInputStream.java:112)\n",
            "\tat Tokenizer.loadTokenMapping(Tokenizer.java:203)\n",
            "\tat Tokenizer.main(Tokenizer.java:927)\n",
            "\n",
            "real\t0m7.472s\n",
            "user\t0m13.060s\n",
            "sys\t0m1.114s\n",
            "cat: models/NEW/language.txt: No such file or directory\n",
            "Detected Language: \u001b[0K\n",
            "\u001b[32m===Phrasal Segmentation===\u001b[m\n",
            "=== Current Settings ===\n",
            "Segmentation Model Path = models/NEW/segmentation.model\n",
            "After the phrasal segmentation, only following phrases will be highlighted with <phrase> and </phrase>\n",
            "\tQ(multi-word phrases) >= 0.700000\n",
            "\tQ(single-word phrases) >= 1.000000\n",
            "=======\n",
            "[Warning] failed to open models/NEW/segmentation.model under parameters = rb\n",
            "./phrasal_segmentation.sh: line 91: 35691 Segmentation fault      (core dumped) ./bin/segphrase_segment --pos_tag --thread $THREAD --model $SEGMENTATION_MODEL --highlight-multi $HIGHLIGHT_MULTI --highlight-single $HIGHLIGHT_SINGLE\n",
            "\n",
            "real\t0m0.037s\n",
            "user\t0m0.007s\n",
            "sys\t0m0.028s\n",
            "\u001b[32m===Generating Output===\u001b[m\n",
            "[Fatal Error] Load Limit Exceeded! You may want to modify the load limit in the Tokenizer.java\n",
            "\n",
            "real\t0m0.954s\n",
            "user\t0m1.638s\n",
            "sys\t0m0.087s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "UWXI7EwAbP1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./auto_phrase.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvDlb1u5Ps81",
        "outputId": "ca1846d5-bc2a-4bf5-ad40-84bb76b9a262"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32m===Compilation===\u001b[m\n",
            "\u001b[32m===Tokenization===\u001b[m\n",
            "\n",
            "real\t0m20.066s\n",
            "user\t0m33.125s\n",
            "sys\t0m1.853s\n",
            "Detected Language: EN\u001b[0K\n",
            "Current step: Tokenizing wikipedia phrases...\u001b[0K\n",
            "No provided expert labels.\u001b[0K\n",
            "\u001b[32m===Part-Of-Speech Tagging===\u001b[m\n",
            "Current step: Merging...\u001b[0K\n",
            "\u001b[32m===AutoPhrasing===\u001b[m\n",
            "=== Current Settings ===\n",
            "Iterations = 2\n",
            "Minimum Support Threshold = 10\n",
            "Maximum Length Threshold = 6\n",
            "POS-Tagging Mode Enabled\n",
            "Number of threads = 10\n",
            "Labeling Method = DPDN\n",
            "\tAuto labels from knowledge bases\n",
            "\tMax Positive Samples = -1\n",
            "=======\n",
            "Loading data...\n",
            "# of total tokens = 5985522\n",
            "max word token id = 73460\n",
            "# of documents = 127600\n",
            "# of distinct POS tags = 57\n",
            "Mining frequent phrases...\n",
            "selected MAGIC = 73471\n",
            "# of frequent phrases = 145728\n",
            "Extracting features...\n",
            "Constructing label pools...\n",
            "\tThe size of the positive pool = 15372\n",
            "\tThe size of the negative pool = 129174\n",
            "# truth patterns = 160138\n",
            "Estimating Phrase Quality...\n",
            "Segmenting...\n",
            "Rectifying features...\n",
            "Estimating Phrase Quality...\n",
            "Segmenting...\n",
            "Dumping results...\n",
            "Done.\n",
            "\n",
            "real\t1m33.776s\n",
            "user\t2m10.419s\n",
            "sys\t0m14.538s\n",
            "\u001b[32m===Saving Model and Results===\u001b[m\n",
            "\u001b[32m===Generating Output===\u001b[m\n"
          ]
        }
      ]
    }
  ]
}